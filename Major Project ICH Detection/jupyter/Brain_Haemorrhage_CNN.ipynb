{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zR6aee__ckkD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras import datasets, layers, models,Model\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from multiprocessing import Pool\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iWfBK2cLj_Cv"
      },
      "outputs": [],
      "source": [
        "def load_samples():\n",
        "    data = pd.read_csv(\"data\\csv\\sampled_dataset_final.csv\",index_col=0)  \n",
        "    c=0\n",
        "    for row in data.itertuples(index=False):\n",
        "      samples.append([x for x in row])\n",
        "      c+=1\n",
        "      # if(c==): # to break when required sample is already pulled\n",
        "      #   break\n",
        "    return samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mCr_d96o7IB",
        "outputId": "2e373e03-9004-40df-b950-9dfe6417a320"
      },
      "outputs": [],
      "source": [
        "samples=[]\n",
        "samples=load_samples()\n",
        "print (samples[0:5])\n",
        "print(len(samples))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "z17y-1jYTPzO"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "  model=models.Sequential()\n",
        "  model.add(layers.Conv2D(16,kernel_size=(3, 3), activation='relu', input_shape=(275,275,1)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  # normliztion to use overfitting use drop out only in full connected network ie dense layer\n",
        "  \n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Dense(16, activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Dense(5,activation='sigmoid'))\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "be7QDcKFdLw6"
      },
      "outputs": [],
      "source": [
        "bone_model=create_model()\n",
        "brain_model=create_model()\n",
        "blood_model=create_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4CtyNIJZAk1D"
      },
      "outputs": [],
      "source": [
        "combined=layers.concatenate([bone_model.output,brain_model.output,blood_model.output])\n",
        "combined_model = layers.Dense(15, activation=\"relu\")(combined)\n",
        "combined_model = layers.Dense(5, activation=\"sigmoid\")(combined_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "x_e1nUZQAAVm"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs=[bone_model.input, brain_model.input,blood_model.input], outputs=combined_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "B2pd0U8_IoRn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " conv2d_input (InputLayer)      [(None, 275, 275, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_3_input (InputLayer)    [(None, 275, 275, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_6_input (InputLayer)    [(None, 275, 275, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 273, 273, 16  160         ['conv2d_input[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 273, 273, 16  160         ['conv2d_3_input[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 273, 273, 16  160         ['conv2d_6_input[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 273, 273, 16  64         ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 273, 273, 16  64         ['conv2d_3[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 273, 273, 16  64         ['conv2d_6[0][0]']               \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 136, 136, 16  0          ['batch_normalization[0][0]']    \n",
            " ing2D)                         )                                                                 \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 136, 136, 16  0          ['batch_normalization_7[0][0]']  \n",
            " oling2D)                       )                                                                 \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 136, 136, 16  0          ['batch_normalization_14[0][0]'] \n",
            " oling2D)                       )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 136, 136, 16  64         ['average_pooling2d[0][0]']      \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 136, 136, 16  64         ['average_pooling2d_3[0][0]']    \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 136, 136, 16  64         ['average_pooling2d_6[0][0]']    \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 134, 134, 64  9280        ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 134, 134, 64  9280        ['batch_normalization_8[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 134, 134, 64  9280        ['batch_normalization_15[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 134, 134, 64  256        ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 134, 134, 64  256        ['conv2d_4[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 134, 134, 64  256        ['conv2d_7[0][0]']               \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 67, 67, 64)  0           ['batch_normalization_2[0][0]']  \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 67, 67, 64)  0           ['batch_normalization_9[0][0]']  \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (AveragePo  (None, 67, 67, 64)  0           ['batch_normalization_16[0][0]'] \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 65, 65, 128)  73856       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 65, 65, 128)  73856       ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 65, 65, 128)  73856       ['average_pooling2d_7[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 65, 65, 128)  512        ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 65, 65, 128)  512        ['conv2d_5[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 65, 65, 128)  512        ['conv2d_8[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 32, 32, 128)  0          ['batch_normalization_3[0][0]']  \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 32, 32, 128)  0          ['batch_normalization_10[0][0]'] \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (AveragePo  (None, 32, 32, 128)  0          ['batch_normalization_17[0][0]'] \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 32, 32, 128)  512        ['average_pooling2d_2[0][0]']    \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 32, 32, 128)  512        ['average_pooling2d_5[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 32, 32, 128)  512        ['average_pooling2d_8[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 131072)       0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 131072)       0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 131072)       0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          16777344    ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 128)          16777344    ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 128)          16777344    ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 128)         512         ['dense[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 128)         512         ['dense_3[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 128)         512         ['dense_6[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 128)          0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 128)          0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 128)          0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 16)           2064        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 16)           2064        ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 16)           2064        ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 16)          64          ['dense_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16)          64          ['dense_4[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 16)          64          ['dense_7[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 16)           0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 16)           0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 16)           0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 5)            85          ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 5)            85          ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 5)            85          ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 15)           0           ['dense_2[0][0]',                \n",
            "                                                                  'dense_5[0][0]',                \n",
            "                                                                  'dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 15)           240         ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 5)            80          ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 50,594,639\n",
            "Trainable params: 50,591,663\n",
            "Non-trainable params: 2,976\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrrEG7l1H4rh",
        "outputId": "f4f58c0b-abcd-41e4-b4b9-e1cac69ae34c"
      },
      "outputs": [],
      "source": [
        "label.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "C1Jeh7MNpf2O"
      },
      "outputs": [],
      "source": [
        "#Changing file directory and patience set to 5 & saving only best models\n",
        "filepath=\"data\\models\\weights-improvement-{epoch:02d}-{accuracy:02f}.hdf5\"\n",
        "earlystop=EarlyStopping(monitor='accuracy', mode='max',  patience=5)\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='accuracy', save_best_only=True, mode='max')\n",
        "callbacks_list = [earlystop,checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ldol3gqpCX1C"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Use this generator functions\n",
        "def generator(samples, batch_size=32):\n",
        "    \"\"\"\n",
        "    Yields the next training batch.\n",
        "    Suppose `samples` is an array [[image1_filename,label1], [image2_filename,label2],...].\n",
        "    \"\"\"\n",
        "    num_samples = len(samples)\n",
        "    while True: # Loop forever so the generator never terminates\n",
        "        shuffle(samples)\n",
        " \n",
        "        # Get index to start each batch: [0, batch_size, 2*batch_size, ..., max multiple of batch_size &lt;= num_samples]\n",
        "        for offset in range(0, num_samples, batch_size):\n",
        "            # Get the samples you'll use in this batch\n",
        "            batch_samples = samples[offset:offset+batch_size]\n",
        " \n",
        "            # Initialise X_train and y_train arrays for this batch\n",
        "            X_train = []\n",
        "            X_trains=[]\n",
        "            X_trainss=[]\n",
        "            y_train = []\n",
        "            \n",
        "            # For each example\n",
        "            for batch_sample in batch_samples:\n",
        "                # Load image (X)\n",
        "                filename = 'data\\\\temp\\\\bone_window\\\\'+batch_sample[0]+'.png'\n",
        "                image = cv2.imread(filename)\n",
        "                image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                # Read label (y)\n",
        "                y = [x for x in batch_sample[2:]]\n",
        "                X_train.append(image)\n",
        "                y_train.append(y)\n",
        "\n",
        "                filename = 'data\\\\temp\\\\brain_window\\\\'+batch_sample[0]+'.png'\n",
        "                image = cv2.imread(filename)\n",
        "                image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "                X_trains.append(image)\n",
        "\n",
        "                filename = 'data\\\\temp\\\\blood_window\\\\'+batch_sample[0]+'.png'\n",
        "                image = cv2.imread(filename)\n",
        "                image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "                X_trainss.append(image)\n",
        " \n",
        "            # Make sure they're numpy arrays (as opposed to lists)\n",
        "            X_train = np.array(X_train)/255.0\n",
        "            X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
        "\n",
        "            X_trains = np.array(X_trains)/255.0\n",
        "            X_trains = X_trains.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
        "\n",
        "            X_trainss = np.array(X_trainss)/255.0\n",
        "            X_trainss = X_trainss.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
        "\n",
        "\n",
        "            # X_train=tf.convert/_to_tensor(X_train)\n",
        "            y_train = np.array(y_train)\n",
        "            # y_train=tf.convert_to_tensor(y_train)\n",
        "            # X_train=X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\n",
        "            # The generator-y part: yield the next training batch            \n",
        "            yield [X_train,X_trains,X_trainss], y_train\n",
        "\n",
        "            \n",
        "train_datagen = generator(samples[0:int(len(samples)*0.8)],batch_size=32)\n",
        "validation_generator = generator(samples[int(len(samples)*0.8):], batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHX74k98CZ1s",
        "outputId": "0d89e533-7ffa-4e9a-ccaa-1b1dba5a82f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/11\n",
            "353/353 [==============================] - 2305s 7s/step - loss: 0.3636 - accuracy: 0.2213 - val_loss: 0.4143 - val_accuracy: 0.1577\n",
            "Epoch 2/11\n",
            "353/353 [==============================] - 2027s 6s/step - loss: 0.3158 - accuracy: 0.2212 - val_loss: 0.3541 - val_accuracy: 0.2259\n",
            "Epoch 3/11\n",
            "353/353 [==============================] - 1718s 5s/step - loss: 0.3057 - accuracy: 0.2309 - val_loss: 0.4367 - val_accuracy: 0.2198\n",
            "Epoch 4/11\n",
            "353/353 [==============================] - 1718s 5s/step - loss: 0.2965 - accuracy: 0.2340 - val_loss: 0.3518 - val_accuracy: 0.2408\n",
            "Epoch 5/11\n",
            "353/353 [==============================] - 1722s 5s/step - loss: 0.2903 - accuracy: 0.2392 - val_loss: 0.4456 - val_accuracy: 0.0977\n",
            "Epoch 6/11\n",
            "353/353 [==============================] - 1663s 5s/step - loss: 0.2756 - accuracy: 0.2525 - val_loss: 0.3574 - val_accuracy: 0.2425\n",
            "Epoch 7/11\n",
            "353/353 [==============================] - 1597s 5s/step - loss: 0.2616 - accuracy: 0.2584 - val_loss: 0.3779 - val_accuracy: 0.1325\n",
            "Epoch 8/11\n",
            "353/353 [==============================] - 1689s 5s/step - loss: 0.2526 - accuracy: 0.2699 - val_loss: 0.3171 - val_accuracy: 0.2266\n",
            "Epoch 9/11\n",
            "353/353 [==============================] - 1690s 5s/step - loss: 0.2392 - accuracy: 0.2776 - val_loss: 0.3952 - val_accuracy: 0.1871\n",
            "Epoch 10/11\n",
            "353/353 [==============================] - 1804s 5s/step - loss: 0.2368 - accuracy: 0.2708 - val_loss: 0.6266 - val_accuracy: 0.0575\n",
            "Epoch 11/11\n",
            "353/353 [==============================] - 1690s 5s/step - loss: 0.2242 - accuracy: 0.2863 - val_loss: 0.3914 - val_accuracy: 0.1818\n"
          ]
        }
      ],
      "source": [
        "# Model Training Cell\n",
        "# batch=32\n",
        "# steps_per_epoch = TotalTrainingSamples / TrainingBatchSize\n",
        "# validation_steps = TotalvalidationSamples / ValidationBatchSize\n",
        "history=model.fit(\n",
        "        train_datagen,\n",
        "        epochs=11, steps_per_epoch=int(len(samples)*0.8/32)\n",
        "        ,validation_steps=int(0.2 * len(samples)/32)\n",
        "        ,callbacks=callbacks_list\n",
        "        ,validation_data=validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/temp/weights-improvement-06-0.633729.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuksvSACtcEP",
        "outputId": "72655d5e-2a06-42ea-de25-1af9231571b9"
      },
      "outputs": [],
      "source": [
        "filename = '/content/drive/MyDrive/temp/bone_window/'+'ID_000a050f3'+'.png'              \n",
        "X_train = []\n",
        "image = cv2.imread(filename)\n",
        "image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "X_train.append(image)\n",
        "X_train = np.array(X_train)/255.0\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
        "\n",
        "filenames = '/content/drive/MyDrive/temp/brain_window/'+'ID_000a050f3'+'.png'             \n",
        "X_trains = []\n",
        "image = cv2.imread(filename)\n",
        "image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "X_trains.append(image)\n",
        "X_trains = np.array(X_train)/255.0\n",
        "X_trains = X_trains.reshape(X_trains.shape[0], X_trains.shape[1], X_trains.shape[2], 1)\n",
        "\n",
        "filenames = '/content/drive/MyDrive/temp/blood_window/'+'ID_000a050f3'+'.png'\n",
        "X_trainss = []\n",
        "image = cv2.imread(filenames)\n",
        "image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "X_trainss.append(image)\n",
        "X_trainss = np.array(X_trainss)/255.0\n",
        "X_trainss = X_trainss.reshape(X_trains.shape[0], X_trains.shape[1], X_trains.shape[2], 1)\n",
        "\n",
        "model.predict([X_train,X_trains,X_trainss])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "3oGaI8sRuAfM",
        "outputId": "697258d7-dbee-44aa-8e8b-e9bc6f11b669"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "7vv_0sWquYnZ",
        "outputId": "31dc007e-8cf8-4ff2-f244-dad614b52ba5"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "UNUSED CELLS BELOW>>>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jjuG4dnpv6Sq"
      },
      "outputs": [],
      "source": [
        "#Dont Use This Cell \n",
        "#Without using Pool and multiprocessing. Doesnt cause Memory overload\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Resources/sampled_dataset_final.csv\",index_col=0)\n",
        "samples=[]  \n",
        "c=0\n",
        "bone_input=[]\n",
        "brain_input=[]\n",
        "blood_input=[]\n",
        "label=[]\n",
        "for row in data.itertuples(index=False):\n",
        "    samples.append([x for x in row])\n",
        "    c+=1\n",
        "    if(c==6000):\n",
        "      break\n",
        "for batch_sample in samples:\n",
        "                # Load image (X)\n",
        "  filename_bone = '/content/temp/bone_window/'+batch_sample[0]+'.png'\n",
        "  filename_brain = '/content/temp/brain_window/'+batch_sample[0]+'.png'\n",
        "  filename_blood = '/content/temp/blood_window/'+batch_sample[0]+'.png'\n",
        "  image = cv2.imread(filename_bone)\n",
        "  image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  bone_input.append(image)\n",
        "\n",
        "  # y = [x for x in batch_sample[2:]]\n",
        "  image = cv2.imread(filename_brain)\n",
        "  image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  brain_input.append(image)\n",
        "\n",
        "  image = cv2.imread(filename_blood)\n",
        "  image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  blood_input.append(image)\n",
        "\n",
        "  label.append([x for x in batch_sample[2:]])\n",
        "bone_input = np.array(bone_input)/255.0\n",
        "bone_input = bone_input.reshape(bone_input.shape[0], bone_input.shape[1], bone_input.shape[2], 1)\n",
        "\n",
        "brain_input = np.array(brain_input)/255.0\n",
        "brain_input = brain_input.reshape(brain_input.shape[0], brain_input.shape[1], brain_input.shape[2], 1)\n",
        "\n",
        "blood_input = np.array(blood_input)/255.0\n",
        "blood_input = blood_input.reshape(brain_input.shape[0], brain_input.shape[1], brain_input.shape[2], 1)\n",
        "\n",
        "# m=tf.convert_to_tensor(m)\n",
        "label= np.array(label)\n",
        "# n=tf.convert_to_tensor(n)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#It is one of two cell to load images faster using multiprocessing if upper cell is executed no need to run\n",
        "#Part of Pool Cell\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Resources/sampled_dataset_final.csv\",index_col=0)\n",
        "samples=[]  \n",
        "c=0\n",
        "bone_input=[]\n",
        "brain_input=[]\n",
        "blood_input=[]\n",
        "label=[]\n",
        "for row in data.itertuples(index=False):\n",
        "    samples.append([x for x in row])\n",
        "    c+=1\n",
        "    # if(c==5):\n",
        "    #   break\n",
        "\n",
        "def load_bone_images(samples):\n",
        "  filename_bone = '/content/temp/bone_window/'+samples[0]+'.png'\n",
        "  image = cv2.imread(filename_bone)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  return image\n",
        "\n",
        "def load_brain_images(samples):\n",
        "  filename_bone = '/content/temp/brain_window/'+samples[0]+'.png'\n",
        "  image = cv2.imread(filename_bone)\n",
        "  image=  cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  return image\n",
        "\n",
        "def load_blood_images(samples):\n",
        "  filename_bone = '/content/temp/blood_window/'+samples[0]+'.png'\n",
        "  image = cv2.imread(filename_bone)\n",
        "  image=  cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  return image\n",
        "\n",
        "def load_label(samples):\n",
        "  # label.append([x for x in batch_sample[2:]])\n",
        "  return [x for x in samples[2:]];"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#It is the second portion to load images using multiprocessing\n",
        "#Using Pool causes Memory Overload\n",
        "\n",
        "\n",
        "bone_input=[]\n",
        "brain_input=[]\n",
        "blood_input=[]\n",
        "label=[]\n",
        "with Pool(2) as p:\n",
        "  bone_input.append(p.map(load_bone_images, samples))\n",
        "  bone_input=bone_input[0]\n",
        "  bone_input = np.array(bone_input)/255.0\n",
        "  bone_input = bone_input.reshape(bone_input.shape[0], bone_input.shape[1], bone_input.shape[2], 1)\n",
        "  p.close()\n",
        "\n",
        "with Pool(2) as p:\n",
        "  brain_input.append(p.map(load_brain_images, samples))\n",
        "  brain_input=brain_input[0]\n",
        "  brain_input = np.array(brain_input)/255.0\n",
        "  brain_input = brain_input.reshape(bone_input.shape[0], bone_input.shape[1], bone_input.shape[2], 1)\n",
        "  p.close()\n",
        "\n",
        "with Pool(2) as p:\n",
        "  blood_input.append(p.map(load_brain_images, samples))\n",
        "  blood_input=blood_input[0]\n",
        "  blood_input = np.array(blood_input)/255.0\n",
        "  blood_input = blood_input.reshape(brain_input.shape[0], brain_input.shape[1], brain_input.shape[2], 1)\n",
        "  p.close()\n",
        "\n",
        "with Pool(2) as p:\n",
        "  label.append(p.map(load_label,samples))\n",
        "  label=label[0]\n",
        "  label= np.array(label)\n",
        "  p.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Brain Haemorrhage CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
